{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "VJUb_7D2TerM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "EAKwFe1mTfqp"
   },
   "outputs": [],
   "source": [
    "class MLAPI:\n",
    "    device = None\n",
    "    nvidia = False\n",
    "    dataset_name = None\n",
    "    dataset = None\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, checkpoint=\"\"):\n",
    "        try:\n",
    "            subprocess.check_output('nvidia-smi')\n",
    "            nvidia = True\n",
    "            print(\"Nvidia drivers available!\")\n",
    "        except Exception: \n",
    "            # this command not being found can raise quite a few \n",
    "            # different errors depending on the configuration\n",
    "            print('No Nvidia GPU in system!')\n",
    "        try:\n",
    "            self.device = torch.device('cuda:0')\n",
    "            print(\"GPU available!\")\n",
    "        except:\n",
    "            print(\"No GPU available in system!\")\n",
    "        \n",
    "\n",
    "    def set_local_csv_dataset(self, dataset=\"./Data/archive 2/Iris.csv\"):\n",
    "        self.dataset_name = dataset\n",
    "        try:\n",
    "            self.dataset = pd.read_csv(self.dataset_name)\n",
    "        except:\n",
    "            print(\"Not CSV\")\n",
    "\n",
    "    def set_local_json_dataset(self, dataset):\n",
    "        pass\n",
    "\n",
    "    def logistic_regression(self,label, lr=1e-4, test_size=0.25, random_state=42, columns=None, max_epochs=100):\n",
    "        df_encoded = pd.get_dummies(self.dataset, drop_first=True)\n",
    "        y = self.dataset[label]\n",
    "        if columns == None:\n",
    "            #assume all other columns and set X_columns to all features not label\n",
    "            X_columns = [col for col in self.dataset.columns if label not in col]\n",
    "        else:\n",
    "            # use only given columns\n",
    "            X_columns = columns\n",
    "        X = self.dataset[X_columns]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        self.model = LogisticRegression(max_iter=max_epochs)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        accuracy = self.model.score(X_test, y_test)\n",
    "        print(f\"Model Accuracy: {accuracy}\")\n",
    "        return self.model\n",
    "\n",
    "    def linear_regression(self,label, lr=1e-4, test_size=0.25, random_state=42, columns=None, max_epochs=100):\n",
    "        df_encoded = pd.get_dummies(self.dataset, drop_first=True)\n",
    "\n",
    "        #TODO: get columns from df_encoded if categorical data that is one hot encoded\n",
    "        \n",
    "        y = df_encoded[label]\n",
    "        if columns == None:\n",
    "            #assume all other columns and set X_columns to all features not label\n",
    "            X_columns = [col for col in df_encoded.columns if label not in col]\n",
    "        else:\n",
    "            # use only given columns\n",
    "            X_columns = columns\n",
    "        X = df_encoded[X_columns]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        self.model = LinearRegression()\n",
    "        self.model.fit(X_train, y_train)\n",
    "        accuracy = self.model.score(X_test, y_test)\n",
    "        print(f\"Model Accuracy: {accuracy}\")\n",
    "        return self.model\n",
    "\n",
    "    def svm(self,label, lr=1e-4, test_size=0.25, random_state=42, columns=None, max_epochs=100):\n",
    "        # TODO: METHOD STUB\n",
    "        pass\n",
    "\n",
    "    def decision_tree(self,label, lr=1e-4, test_size=0.25, random_state=42, columns=None, max_epochs=100):\n",
    "        y = self.dataset[label]\n",
    "        if columns == None:\n",
    "            #assume all other columns and set X_columns to all features not label\n",
    "            X_columns = [col for col in self.dataset.columns if label not in col]\n",
    "        else:\n",
    "            # use only given columns\n",
    "            X_columns = columns\n",
    "        X = self.dataset[X_columns]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        self.model = DecisionTreeClassifier(random_state = random_state)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = self.model.score(X_test, y_test)\n",
    "        print(f\"Decision Tree Model Accuracy: {accuracy}\")\n",
    "        return self.model\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Nvidia GPU in system!\n",
      "GPU available!\n",
      "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
      "0      1            5.1           3.5            1.4           0.2   \n",
      "1      2            4.9           3.0            1.4           0.2   \n",
      "2      3            4.7           3.2            1.3           0.2   \n",
      "3      4            4.6           3.1            1.5           0.2   \n",
      "4      5            5.0           3.6            1.4           0.2   \n",
      "..   ...            ...           ...            ...           ...   \n",
      "145  146            6.7           3.0            5.2           2.3   \n",
      "146  147            6.3           2.5            5.0           1.9   \n",
      "147  148            6.5           3.0            5.2           2.0   \n",
      "148  149            6.2           3.4            5.4           2.3   \n",
      "149  150            5.9           3.0            5.1           1.8   \n",
      "\n",
      "            Species  \n",
      "0       Iris-setosa  \n",
      "1       Iris-setosa  \n",
      "2       Iris-setosa  \n",
      "3       Iris-setosa  \n",
      "4       Iris-setosa  \n",
      "..              ...  \n",
      "145  Iris-virginica  \n",
      "146  Iris-virginica  \n",
      "147  Iris-virginica  \n",
      "148  Iris-virginica  \n",
      "149  Iris-virginica  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(80982) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "api = MLAPI()\n",
    "api.set_local_csv_dataset()\n",
    "print(api.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 1.0\n",
      "LogisticRegression(max_iter=700)\n",
      "Model Accuracy: 0.9469908228307156\n",
      "LinearRegression()\n",
      "Decision Tree Model Accuracy: 1.0\n",
      "DecisionTreeClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(api.logistic_regression('Species', max_epochs=700))\n",
    "print(api.linear_regression('Species_Iris-versicolor', max_epochs=700))\n",
    "print(api.decision_tree('Species', max_epochs=700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(82572) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ML_API.ipynb to script\n",
      "[NbConvertApp] Writing 4917 bytes to ML_API.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script 'ML_API.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
