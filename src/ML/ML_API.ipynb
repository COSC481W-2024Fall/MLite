{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VJUb_7D2TerM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EAKwFe1mTfqp"
   },
   "outputs": [],
   "source": [
    "class MLAPI:\n",
    "    device = None\n",
    "    nvidia = False\n",
    "    dataset_name = None\n",
    "    dataset = None\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, checkpoint=\"\"):\n",
    "        try:\n",
    "            subprocess.check_output('nvidia-smi')\n",
    "            nvidia = True\n",
    "            print(\"Nvidia drivers available!\")\n",
    "        except Exception: \n",
    "            # this command not being found can raise quite a few \n",
    "            # different errors depending on the configuration\n",
    "            print('No Nvidia GPU in system!')\n",
    "        try:\n",
    "            self.device = torch.device('cuda:0')\n",
    "            print(\"GPU available!\")\n",
    "        except:\n",
    "            print(\"No GPU available in system!\")\n",
    "        \n",
    "\n",
    "    def set_local_csv_dataset(self, dataset=None):\n",
    "        self.dataset_name = dataset\n",
    "        if dataset == None:\n",
    "            from sklearn import datasets\n",
    "            iris = datasets.load_iris()\n",
    "            irisdf = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                                 columns= iris['feature_names'] + ['target'])\n",
    "            self.dataset = irisdf\n",
    "        else:\n",
    "            try:\n",
    "                self.dataset = pd.read_csv(self.dataset_name)\n",
    "            except:\n",
    "                print(\"Not CSV\")\n",
    "\n",
    "    def set_local_json_dataset(self, dataset):\n",
    "        pass\n",
    "\n",
    "    def logistic_regression(self,label, lr=1e-4, test_size=0.25, random_state=42, columns=None, max_epochs=100):\n",
    "        df_encoded = pd.get_dummies(self.dataset, drop_first=True)\n",
    "        y = self.dataset[label]\n",
    "        if columns == None:\n",
    "            #assume all other columns and set X_columns to all features not label\n",
    "            X_columns = [col for col in self.dataset.columns if label not in col]\n",
    "        else:\n",
    "            # use only given columns\n",
    "            X_columns = columns\n",
    "        X = self.dataset[X_columns]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        self.model = LogisticRegression(max_iter=max_epochs)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        accuracy = self.model.score(X_test, y_test)\n",
    "        print(f\"Model Accuracy: {accuracy}\")\n",
    "        return self.model\n",
    "\n",
    "    def linear_regression(self,label, lr=1e-4, test_size=0.25, random_state=42, columns=None, max_epochs=100):\n",
    "        df_encoded = pd.get_dummies(self.dataset, drop_first=True)\n",
    "\n",
    "        #TODO: get columns from df_encoded if categorical data that is one hot encoded\n",
    "        \n",
    "        y = df_encoded[label]\n",
    "        if columns == None:\n",
    "            #assume all other columns and set X_columns to all features not label\n",
    "            X_columns = [col for col in df_encoded.columns if label not in col]\n",
    "        else:\n",
    "            # use only given columns\n",
    "            X_columns = columns\n",
    "        X = df_encoded[X_columns]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        self.model = LinearRegression()\n",
    "        self.model.fit(X_train, y_train)\n",
    "        accuracy = self.model.score(X_test, y_test)\n",
    "        print(f\"Model Accuracy: {accuracy}\")\n",
    "        return self.model\n",
    "\n",
    "    def svm(self,label, lr=1e-4, test_size=0.25, random_state=42, columns=None, max_epochs=100):\n",
    "        # TODO: METHOD STUB\n",
    "        pass\n",
    "\n",
    "    def decision_tree(self,label, lr=1e-4, test_size=0.25, random_state=42, columns=None, max_epochs=100):\n",
    "        y = self.dataset[label]\n",
    "        if columns == None:\n",
    "            #assume all other columns and set X_columns to all features not label\n",
    "            X_columns = [col for col in self.dataset.columns if label not in col]\n",
    "        else:\n",
    "            # use only given columns\n",
    "            X_columns = columns\n",
    "        X = self.dataset[X_columns]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        self.model = DecisionTreeClassifier(random_state = random_state)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = self.model.score(X_test, y_test)\n",
    "        print(f\"Decision Tree Model Accuracy: {accuracy}\")\n",
    "        return self.model\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ML_API.ipynb to script\n",
      "[NbConvertApp] Writing 5238 bytes to ML_API.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script 'ML_API.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
